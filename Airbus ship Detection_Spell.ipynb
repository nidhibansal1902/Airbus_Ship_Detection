{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread\n",
    "from numpy import expand_dims\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://www.github.com/matterport/Mask_RCNN.git\n",
    "os.chdir('Mask_RCNN')\n",
    "#!python setup.py -q install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.visualize import display_top_masks\n",
    "from mrcnn.utils import extract_bboxes\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks1 = pd.read_csv('/spell/ship_segmentations.csv') # Markers for ships\n",
    "marks1.reset_index(drop=True,inplace=True)\n",
    "marks_unique = marks1[marks1.EncodedPixels.notnull()]\n",
    "\n",
    "marks=marks_unique[1:100]\n",
    "marks.reset_index(drop=True,inplace=True)\n",
    "images =list(marks.ImageId)\n",
    "marks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_marks=marks_unique[100:130]\n",
    "test_marks.reset_index(drop=True,inplace=True)\n",
    "\n",
    "test_images =list(test_marks.ImageId)\n",
    "test_marks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks[2:3].EncodedPixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '/spell/train'\n",
    "TEST_DATA_PATH = '/spell/test'\n",
    "\n",
    "IMAGE_WIDTH = 768\n",
    "IMAGE_HEIGHT = 768\n",
    "SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShipDetection(Dataset):\n",
    "    \"\"\"Dataset class for training our dataset.\n",
    "    \"\"\"        \n",
    "    # load the dataset definitions\n",
    "    def load_dataset(self, images_list, marks_ann, dataset_dir,orig_height, orig_width):\n",
    "         # Add classes\n",
    "        self.add_class('ship', 1, 'Ship')\n",
    "       # print(marks_ann)\n",
    "        for i, fp in enumerate(images_list):            \n",
    "            annotations=marks_ann.loc[marks_ann['ImageId'] == fp].EncodedPixels\n",
    "            self.add_image('ship', image_id=i, path=os.path.join(dataset_dir, fp), \n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "            \n",
    "        \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        print(info)\n",
    "        return info['path']\n",
    "\n",
    "    #Load Image\n",
    "    def load_image(self, image_id):\n",
    "        info=self.image_info[image_id]\n",
    "        #print(info)\n",
    "        image = imread(info['path'])\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    #Load Mask\n",
    "    def load_mask(self, image_id):\n",
    "        #print(self.image_info)\n",
    "        info=self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "#         print(image_id, annotations)\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                mask[:, :, i] = rle_decode(a,SHAPE)\n",
    "                class_ids[i] = 1\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train set\n",
    "train_set = ShipDetection()\n",
    "train_set.load_dataset(images,marks, TRAIN_DATA_PATH, IMAGE_HEIGHT,IMAGE_WIDTH)\n",
    "train_set.prepare()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare test set\n",
    "test_set = ShipDetection()\n",
    "test_set.load_dataset(test_images,test_marks, TEST_DATA_PATH, IMAGE_HEIGHT,IMAGE_WIDTH)\n",
    "test_set.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code to check if image loading, masking and boxing works properly on not\n",
    "# load an image\n",
    "image_id = 40\n",
    "image = train_set.load_image(image_id)\n",
    "#plt.title(\"Actual\")\n",
    "#plt.imshow(image)\n",
    "\n",
    "\n",
    "# load image mask\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "print(class_ids)\n",
    "# display image with masks and bounding boxes\n",
    "#display_instances(image, bbox, mask, class_ids,  train_set.class_names,show_mask=True,show_bbox=True,title=\"Predicted\",figsize=(8, 8))\n",
    "display_top_masks(image, mask, class_ids, train_set.class_names, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbusConfig(Config):\n",
    "\n",
    "    # Setting other parameters...\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        self.NAME = \"airbus_cfg\"\n",
    "        self.NUM_CLASSES = num_classes\n",
    "        self.STEPS_PER_EPOCH =500\n",
    "        self.IMAGE_MAX_DIM=IMAGE_WIDTH\n",
    "        self.IMAGE_MIN_DIM=IMAGE_HEIGHT\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "config = AirbusConfig(num_classes=2)\n",
    "config.NUM_CLASSES\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "# Load and display using mrcnn model which is interally called all functions\n",
    "image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "        train_set, config, image_id= 25, use_mini_mask=False)\n",
    "log(\"molded_image\", image)\n",
    "log(\"mask\", mask)\n",
    "display_instances(image, bbox, mask, class_ids, train_set.class_names,\n",
    "                            show_bbox=False,show_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('/spell/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=2, layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get latest h5 file directory \n",
    "all_subdirs = [d for d in os.listdir('/spell/Mask_RCNN') if os.path.isdir(d)]\n",
    "latest_subdir = max(all_subdirs, key=os.path.getmtime)\n",
    "print(latest_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test dataset\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\n",
    "    # Setting other parameters...\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        self.NAME = \"airbus_cfg\"\n",
    "        self.NUM_CLASSES = 2\n",
    "        self.GPU_COUNT = 1\n",
    "        self.IMAGES_PER_GPU = 1\n",
    "        self.STEPS_PER_EPOCH=100\n",
    "        self.IMAGE_MAX_DIM=IMAGE_WIDTH\n",
    "        self.IMAGE_MIN_DIM=IMAGE_HEIGHT\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "config_pred = PredictionConfig(2)\n",
    "config_pred.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# create config\n",
    "config_pred = PredictionConfig(num_classes=2)\n",
    "# define the model\n",
    "model_eval = MaskRCNN(mode='inference', model_dir='./', config=config_pred)\n",
    "# load model weights\n",
    "model_eval.load_weights('/spell/Mask_RCNN/' + latest_subdir+ '/mask_rcnn_airbus_cfg_0002.h5', by_name=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(dataset, model, cfg, image_id):\n",
    "    # load image and mask \n",
    "\n",
    "    print(dataset.image_info[image_id][\"path\"])\n",
    "    # load the image and mask\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    bbox = extract_bboxes(mask)  \n",
    "    display_instances(image, bbox, mask,class_ids,dataset.class_names,title=\"Actual\",figsize=(8, 8),show_mask=False)\n",
    "\n",
    "    #Predicted image\n",
    "    scaled_image = mold_image(image, cfg)\n",
    "    # convert image into one sample\n",
    "    sample = expand_dims(scaled_image, 0)\n",
    "    # make prediction\n",
    "    yhat = model.detect(sample, verbose=0)[0]\n",
    "\n",
    "    # Visualize results\n",
    "    r = yhat\n",
    "    display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                       dataset.class_names, r['scores'],title=\"Predicted\",figsize=(8, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions for test dataset\n",
    "plot_actual_vs_predicted(test_set, model_eval, config_pred,  image_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_cells(path):\n",
    "    # load image\n",
    "    image = imread(path)\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title('Actual')\n",
    "    plt.imshow(image)\n",
    "    # convert pixel values (e.g. center)\n",
    "    scaled_image = mold_image(image, config_pred)\n",
    "    # convert image into one sample\n",
    "    sample = expand_dims(scaled_image, 0)\n",
    "    # make prediction\n",
    "    yhat = model_eval.detect(sample, verbose=0)[0]\n",
    "    r = yhat\n",
    "    print(r['class_ids'])\n",
    "    print( r['scores'])\n",
    "    display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                train_set.class_names, r['scores'],title=\"Predicted\",figsize=(8,8),show_mask=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_cells(\"/spell/new/001eb2794.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_cells(\"/spell/new/a97d55a5d.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_cells(\"/spell/new/a9a01bb33.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_cells(\"/spell/new/acb4aa56f.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
